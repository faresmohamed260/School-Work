{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 5193333,
     "sourceType": "datasetVersion",
     "datasetId": 3019642
    }
   ],
   "dockerImageVersionId": 30262,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Name: Fares Mohamed Salah\n",
    "# ID: 22011614"
   ],
   "metadata": {
    "_uuid": "c12b46e6-4c9f-4f13-8cf2-a5d6173e7259",
    "_cell_guid": "d2ec48d7-680b-457c-9cb7-8d2f8fa66207",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "_uuid": "40719b0d-4254-437a-88d7-6edbd9877fe1",
    "_cell_guid": "e7d97d60-1078-4ba2-bc22-62e35bef046f",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import Bidirectional,GRU,LSTM,Embedding\n",
    "from tensorflow.keras.layers import Dense,MultiHeadAttention,LayerNormalization,Embedding,Dropout,Layer\n",
    "from tensorflow.keras import Sequential,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ],
   "metadata": {
    "_uuid": "562ce5b1-17e1-4034-981c-0a4fd6262218",
    "_cell_guid": "0e5d250c-0d37-4fa4-b474-767319b81b29",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:47.281953Z",
     "iopub.execute_input": "2024-12-23T21:40:47.282365Z",
     "iopub.status.idle": "2024-12-23T21:40:53.499393Z",
     "shell.execute_reply.started": "2024-12-23T21:40:47.282329Z",
     "shell.execute_reply": "2024-12-23T21:40:53.498347Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset from the provided file\n",
    "text_file = '/kaggle/input/french/fra.txt'"
   ],
   "metadata": {
    "_uuid": "5590e8b4-af3f-473f-8eda-770e1d04af4e",
    "_cell_guid": "957cbfcb-aa31-417d-8ebf-1c31596e54b3",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:53.500992Z",
     "iopub.execute_input": "2024-12-23T21:40:53.501544Z",
     "iopub.status.idle": "2024-12-23T21:40:53.505802Z",
     "shell.execute_reply.started": "2024-12-23T21:40:53.501514Z",
     "shell.execute_reply": "2024-12-23T21:40:53.504763Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Prepare text pairs (English and French sentences)\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, french = line.split(\"\\t\")\n",
    "    french = \"[start] \" + french + \" [end]\"\n",
    "    text_pairs.append((english, french))"
   ],
   "metadata": {
    "_uuid": "91a096aa-7b05-4b15-bd9c-dd0281b345f9",
    "_cell_guid": "ebacb536-8454-4efe-b6f8-ff3296d14b8e",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:53.507021Z",
     "iopub.execute_input": "2024-12-23T21:40:53.507284Z",
     "iopub.status.idle": "2024-12-23T21:40:53.855245Z",
     "shell.execute_reply.started": "2024-12-23T21:40:53.507260Z",
     "shell.execute_reply": "2024-12-23T21:40:53.854144Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Display a random text pair\n",
    "import random\n",
    "print(random.choice(text_pairs))"
   ],
   "metadata": {
    "_uuid": "d426f130-32eb-4a73-822b-9b48ffdae865",
    "_cell_guid": "3ef2a0c9-d21c-4d90-b178-c5c1b7d3237d",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:53.858054Z",
     "iopub.execute_input": "2024-12-23T21:40:53.858783Z",
     "iopub.status.idle": "2024-12-23T21:40:53.863833Z",
     "shell.execute_reply.started": "2024-12-23T21:40:53.858739Z",
     "shell.execute_reply": "2024-12-23T21:40:53.862752Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "('What did Tom order?', \"[start] Qu'a commandé Tom\\xa0? [end]\")\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Shuffle text pairs and split into training, validation, and test datasets\n",
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ],
   "metadata": {
    "_uuid": "a9841ac0-f459-4967-af29-4718f8ce5ca1",
    "_cell_guid": "f64a4d69-d3c3-4775-82a3-10afae65327b",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:53.864859Z",
     "iopub.execute_input": "2024-12-23T21:40:53.865150Z",
     "iopub.status.idle": "2024-12-23T21:40:54.004098Z",
     "shell.execute_reply.started": "2024-12-23T21:40:53.865126Z",
     "shell.execute_reply": "2024-12-23T21:40:54.003274Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Define characters to strip from the text\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")"
   ],
   "metadata": {
    "_uuid": "7c7b39b9-f5c6-419e-b49e-c22cc29e061c",
    "_cell_guid": "b51ab2f4-c620-41bd-a4b4-71b7a2e47c21",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:54.005240Z",
     "iopub.execute_input": "2024-12-23T21:40:54.005530Z",
     "iopub.status.idle": "2024-12-23T21:40:54.010660Z",
     "shell.execute_reply.started": "2024-12-23T21:40:54.005501Z",
     "shell.execute_reply": "2024-12-23T21:40:54.009522Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom standardization function for text preprocessing\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")"
   ],
   "metadata": {
    "_uuid": "296988a1-41c3-40d7-9db0-60285b9dd9a2",
    "_cell_guid": "33094fe8-9845-4641-9739-3307f55ec8f4",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:54.011856Z",
     "iopub.execute_input": "2024-12-23T21:40:54.012149Z",
     "iopub.status.idle": "2024-12-23T21:40:54.021689Z",
     "shell.execute_reply.started": "2024-12-23T21:40:54.012124Z",
     "shell.execute_reply": "2024-12-23T21:40:54.020812Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Set parameters for text vectorization\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "# Initialize TextVectorization layers for source and target languages\n",
    "source_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# Adapt the vectorization layers using the training data\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_french_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_french_texts)"
   ],
   "metadata": {
    "_uuid": "d09e0755-4810-4dab-aecf-097795f58cd1",
    "_cell_guid": "5277ff10-fea1-4639-b3b2-9bc3a56d431d",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:40:54.022820Z",
     "iopub.execute_input": "2024-12-23T21:40:54.023139Z",
     "iopub.status.idle": "2024-12-23T21:41:07.787815Z",
     "shell.execute_reply.started": "2024-12-23T21:40:54.023113Z",
     "shell.execute_reply": "2024-12-23T21:41:07.786841Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Set batch size for training\n",
    "batch_size = 64\n",
    "\n",
    "# Function to format dataset for training\n",
    "def format_dataset(eng, fre):\n",
    "    eng = source_vectorization(eng)\n",
    "    fre = target_vectorization(fre)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"french\": fre[:, :-1],\n",
    "    }, fre[:, 1:])\n",
    "\n",
    "# Function to create a TensorFlow dataset from text pairs\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, fre_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    fre_texts = list(fre_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fre_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ],
   "metadata": {
    "_uuid": "db40e204-425a-476b-8d6c-6e0a3953a798",
    "_cell_guid": "0561cca4-9f1c-4d47-8ae7-0432f81aefa3",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:41:07.789072Z",
     "iopub.execute_input": "2024-12-23T21:41:07.789369Z",
     "iopub.status.idle": "2024-12-23T21:41:09.124380Z",
     "shell.execute_reply.started": "2024-12-23T21:41:07.789342Z",
     "shell.execute_reply": "2024-12-23T21:41:09.123584Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM Model"
   ],
   "metadata": {
    "_uuid": "0bc151e5-09c7-4b58-8097-90e5a19d0e24",
    "_cell_guid": "b43ec9a9-f66b-4268-8f06-8e7b7f1c930a",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "_uuid": "f8ba4eeb-189e-458f-b374-4966ac5137b8",
    "_cell_guid": "d8904271-f73c-4821-990f-52777158a22f",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ],
   "metadata": {
    "_uuid": "573736d5-5b91-49ab-a75b-487dcf39fb2c",
    "_cell_guid": "5fa7c82d-6144-4349-8536-d837b51eb0cd",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:41:09.127172Z",
     "iopub.execute_input": "2024-12-23T21:41:09.127446Z",
     "iopub.status.idle": "2024-12-23T21:41:09.132775Z",
     "shell.execute_reply.started": "2024-12-23T21:41:09.127419Z",
     "shell.execute_reply": "2024-12-23T21:41:09.131607Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Definition"
   ],
   "metadata": {
    "_uuid": "2a71a636-3b44-4adc-8c7f-35d57f6fc1de",
    "_cell_guid": "e77ff955-bee9-420a-aa90-f9b7a6196fe8",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the LSTM model architecture\n",
    "embed_dim = 256\n",
    "lstm_units = 512\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = Embedding(vocab_size, embed_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(lstm_units, return_state=True)(x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"french\")\n",
    "x = Embedding(vocab_size, embed_dim, mask_zero=True)(decoder_inputs)\n",
    "x = LSTM(lstm_units, return_sequences=True, return_state=True)(x, initial_state=encoder_states)\n",
    "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(x[0])\n",
    "\n",
    "lstm_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "metadata": {
    "_uuid": "c401ec7a-0e9e-4ad2-a54a-458ca7a07190",
    "_cell_guid": "4b311e17-e992-4881-b834-04309599359e",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:41:09.133870Z",
     "iopub.execute_input": "2024-12-23T21:41:09.134149Z",
     "iopub.status.idle": "2024-12-23T21:41:10.823738Z",
     "shell.execute_reply.started": "2024-12-23T21:41:09.134124Z",
     "shell.execute_reply": "2024-12-23T21:41:10.822965Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {
    "_uuid": "171fbd90-6591-4d28-a515-d0e434c6b773",
    "_cell_guid": "0c19cea6-52dd-46ca-8cf4-f9c943f9ceff",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Training parameters and setup\n",
    "epochs = 10\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='lstm_language_translation_checkpoint.hdf5', save_weights_only=True, verbose=1, monitor='val_accuracy')\n",
    "\n",
    "lstm_model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "lstm_model.fit(train_ds, epochs=epochs, callbacks=[checkpoint], validation_data=val_ds)\n",
    "\n",
    "# Saving model weights\n",
    "lstm_model.save_weights(\"lstm_translator.h5\")\n",
    "load_status = lstm_model.load_weights(\"lstm_translator.h5\")"
   ],
   "metadata": {
    "_uuid": "a64d1448-a2a7-4bd7-a7d7-63e7f24e5cc3",
    "_cell_guid": "12040222-75b2-4592-afaa-66f683016c55",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:41:10.824979Z",
     "iopub.execute_input": "2024-12-23T21:41:10.825260Z",
     "iopub.status.idle": "2024-12-23T21:57:42.512274Z",
     "shell.execute_reply.started": "2024-12-23T21:41:10.825234Z",
     "shell.execute_reply": "2024-12-23T21:57:42.511430Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/10\n1828/1828 [==============================] - 109s 55ms/step - loss: 1.6364 - accuracy: 0.4010 - val_loss: 1.3306 - val_accuracy: 0.4804\n\nEpoch 00001: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 2/10\n1828/1828 [==============================] - 98s 54ms/step - loss: 1.2204 - accuracy: 0.5255 - val_loss: 1.1221 - val_accuracy: 0.5566\n\nEpoch 00002: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 3/10\n1828/1828 [==============================] - 98s 54ms/step - loss: 1.0500 - accuracy: 0.5891 - val_loss: 1.0241 - val_accuracy: 0.5978\n\nEpoch 00003: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 4/10\n1828/1828 [==============================] - 98s 54ms/step - loss: 0.9365 - accuracy: 0.6329 - val_loss: 0.9639 - val_accuracy: 0.6239\n\nEpoch 00004: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 5/10\n1828/1828 [==============================] - 98s 53ms/step - loss: 0.8585 - accuracy: 0.6650 - val_loss: 0.9380 - val_accuracy: 0.6377\n\nEpoch 00005: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 6/10\n1828/1828 [==============================] - 98s 53ms/step - loss: 0.7999 - accuracy: 0.6888 - val_loss: 0.9149 - val_accuracy: 0.6460\n\nEpoch 00006: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 7/10\n1828/1828 [==============================] - 98s 53ms/step - loss: 0.7498 - accuracy: 0.7070 - val_loss: 0.8995 - val_accuracy: 0.6513\n\nEpoch 00007: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 8/10\n1828/1828 [==============================] - 98s 54ms/step - loss: 0.7061 - accuracy: 0.7226 - val_loss: 0.8916 - val_accuracy: 0.6534\n\nEpoch 00008: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 9/10\n1828/1828 [==============================] - 98s 53ms/step - loss: 0.6704 - accuracy: 0.7368 - val_loss: 0.8848 - val_accuracy: 0.6561\n\nEpoch 00009: saving model to lstm_language_translation_checkpoint.hdf5\nEpoch 10/10\n1828/1828 [==============================] - 98s 53ms/step - loss: 0.6375 - accuracy: 0.7481 - val_loss: 0.8814 - val_accuracy: 0.6570\n\nEpoch 00010: saving model to lstm_language_translation_checkpoint.hdf5\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation"
   ],
   "metadata": {
    "_uuid": "e20dc305-5513-416c-90d9-ef68b6b7f2da",
    "_cell_guid": "e81f29b0-8372-4cd5-886d-c6c8c521101b",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test data\n",
    "fra_vocab = target_vectorization.get_vocabulary()\n",
    "fra_index_lookup = dict(zip(range(len(fra_vocab)), fra_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence_lstm(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = lstm_model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fra_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence_lstm(input_sentence))"
   ],
   "metadata": {
    "_uuid": "1781a9a5-415d-4320-a45c-9a6002224fdf",
    "_cell_guid": "336e1b67-5b3b-4ff4-b033-3906690e12b7",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:42.513576Z",
     "iopub.execute_input": "2024-12-23T21:57:42.513866Z",
     "iopub.status.idle": "2024-12-23T21:57:43.186461Z",
     "shell.execute_reply.started": "2024-12-23T21:57:42.513840Z",
     "shell.execute_reply": "2024-12-23T21:57:43.185561Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "-\nThey don't serve that here.\n[start] ils ne vont pas ici [end]\n-\nWe will have little snow this winter.\n[start] nous peu de neige cet hiver [end]\n-\nShe was on the verge of tears.\n[start] elle était en colère de [UNK] [end]\n-\nI had a headache, and I took the day off today.\n[start] jai eu un rêve du jour aujourdhui je suis déjà allé à mois [end]\n-\nTom knew that he'd been tricked.\n[start] tom savait quil était [UNK] [end]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluation using the BLEU score\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_fra_texts = [pair[1] for pair in test_pairs]\n",
    "score = 0\n",
    "bleu = 0\n",
    "for i in range(20):\n",
    "    candidate = decode_sequence_lstm(test_eng_texts[i])\n",
    "    reference = test_fra_texts[i].lower()\n",
    "    print(candidate, reference)\n",
    "    score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu += score\n",
    "    print(f\"Score: {score}\")\n",
    "print(f\"\\nBLEU score : {round(bleu, 2)}/20\")"
   ],
   "metadata": {
    "_uuid": "2055fea5-263e-4543-9a4a-998aee944dfb",
    "_cell_guid": "e273ad9a-dcce-417b-93f2-e07d044bc061",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:43.187731Z",
     "iopub.execute_input": "2024-12-23T21:57:43.188082Z",
     "iopub.status.idle": "2024-12-23T21:57:45.822253Z",
     "shell.execute_reply.started": "2024-12-23T21:57:43.188052Z",
     "shell.execute_reply": "2024-12-23T21:57:45.821324Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[start] mon petit de largent est à clé [end] [start] mon petit doigt est enflé. [end]\nScore: 0.38636363636363635\n[start] tu vas avoir du temps [end] [start] tu vas passer un sale quart d'heure. [end]\nScore: 0.37142857142857144\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \nThe hypothesis contains 0 counts of 2-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \nThe hypothesis contains 0 counts of 3-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[start] il est impatient de lire le livre [end] [start] il est impatient de lire le livre. [end]\nScore: 0.31914893617021284\n[start] elles ne peuvent pas te virer [end] [start] ils ne peuvent pas vous virer. [end]\nScore: 0.3488372093023256\n[start] ne me dites pas si vous ne voulez pas [end] [start] ne me le dis pas si tu ne veux pas. [end]\nScore: 0.3137254901960784\n[start] combien dargent astu dépensé pour votre voiture [end] [start] combien d'argent as-tu claqué pour ta voiture ? [end]\nScore: 0.32786885245901637\n[start] nous serons à la manière de garder cela [end] [start] nous essaierons de ne pas laisser cela se reproduire. [end]\nScore: 0.28301886792452824\n[start] nous navons pas pu le droit de résoudre le monde avait pu nous en aller [end] [start] nous n'avons pas pu acheter de places, nous ne sommes donc pas allé au concert. [end]\nScore: 0.2\n[start] Êtesvous pour ou contre notre proposition [end] [start] es-tu pour ou contre la proposition ? [end]\nScore: 0.2727272727272727\n[start] vous [UNK] [end] [start] tu t'exprimes bien. [end]\nScore: 0.4583333333333333\n[start] je nai que jai [UNK] les [UNK] de retour à boston en français [end] [start] je n'ai que des pièces américaines dans ma poche pour le moment. [end]\nScore: 0.21333333333333335\n[start] le prix était [UNK] dune plus petite de la ville [end] [start] le jardin était entouré par une barrière en bois. [end]\nScore: 0.24193548387096778\n[start] les rappelle me sais au travail est un arbre [end] [start] central park est proche de mon lieu de travail. [end]\nScore: 0.27586206896551724\n[start] je suis en chemin [end] [start] je suis en chemin. [end]\nScore: 0.5161290322580645\n[start] nous avons un problème [end] [start] nous avons un problème. [end]\nScore: 0.5\n[start] je pense que cest une serviette sest [UNK] [end] [start] je pense que c'est une loi terrible. [end]\nScore: 0.2857142857142857\n[start] pourquoi ne [UNK] pas ton manteau [end] [start] pourquoi ne retires-tu pas ton manteau ? [end]\nScore: 0.34042553191489366\n[start] je dispose de suffisamment dargent pour faire lacquisition [end] [start] je dispose de suffisamment d'argent pour faire son acquisition. [end]\nScore: 0.2777777777777778\n[start] je me suis parti de ma voiture [UNK] [end] [start] je lave la voiture de mon frère. [end]\nScore: 0.32\n[start] avezvous astu entendu parler de ceci [end] [start] as-tu prévenu ton professeur de cela ? [end]\nScore: 0.32\n\nBLEU score : 6.57/20\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer Model"
   ],
   "metadata": {
    "_uuid": "2ecbf292-ecd9-4780-ab99-b7294ec24c41",
    "_cell_guid": "6009ec7a-1fb1-47e7-91fc-da0fdbde2e40",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "_uuid": "2eb88cf7-4183-4ca3-9d7b-0f35ebe20fb7",
    "_cell_guid": "47e53ed3-9f16-4c9b-8852-0ae089afe2e2",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, Dense, LayerNormalization, MultiHeadAttention, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ],
   "metadata": {
    "_uuid": "5bd7f30e-0efb-4432-9f75-88d9f1c78ab6",
    "_cell_guid": "73caf686-785e-457a-bbb0-973b50ae55f3",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:45.823322Z",
     "iopub.execute_input": "2024-12-23T21:57:45.823606Z",
     "iopub.status.idle": "2024-12-23T21:57:45.828886Z",
     "shell.execute_reply.started": "2024-12-23T21:57:45.823580Z",
     "shell.execute_reply": "2024-12-23T21:57:45.827908Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Definition"
   ],
   "metadata": {
    "_uuid": "dfa010ef-d51a-4a3b-af1f-8177273c2380",
    "_cell_guid": "21121f84-532d-4f10-96c0-4607ca19e061",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Transformer Encoder class\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [Dense(dense_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ],
   "metadata": {
    "_uuid": "7f746a7b-1903-4176-911a-0d90e2fd30b4",
    "_cell_guid": "19527434-e4d2-45e8-8a10-1cade1e38720",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:45.829833Z",
     "iopub.execute_input": "2024-12-23T21:57:45.830114Z",
     "iopub.status.idle": "2024-12-23T21:57:45.842197Z",
     "shell.execute_reply.started": "2024-12-23T21:57:45.830090Z",
     "shell.execute_reply": "2024-12-23T21:57:45.841401Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Transformer Decoder class\n",
    "class TransformerDecoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [Dense(dense_dim, activation=\"relu\"),\n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.layernorm_3 = LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ],
   "metadata": {
    "_uuid": "d0fbf719-e7da-4731-ba96-0bfa0343f4b9",
    "_cell_guid": "c73c48b5-fcca-4fca-8ade-e17077da513c",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:45.843466Z",
     "iopub.execute_input": "2024-12-23T21:57:45.843800Z",
     "iopub.status.idle": "2024-12-23T21:57:45.858830Z",
     "shell.execute_reply.started": "2024-12-23T21:57:45.843766Z",
     "shell.execute_reply": "2024-12-23T21:57:45.858050Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Positional Embedding class\n",
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ],
   "metadata": {
    "_uuid": "5d909438-7072-427c-a889-6660b528d4b5",
    "_cell_guid": "6c35a798-88d5-4fe4-b0fc-86db90e8d00c",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:45.859873Z",
     "iopub.execute_input": "2024-12-23T21:57:45.860160Z",
     "iopub.status.idle": "2024-12-23T21:57:45.875238Z",
     "shell.execute_reply.started": "2024-12-23T21:57:45.860136Z",
     "shell.execute_reply": "2024-12-23T21:57:45.874320Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "# Build the Transformer model architecture\n",
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"french\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = Dropout(0.5)(x)\n",
    "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "metadata": {
    "_uuid": "0f93c453-ddec-4169-90f8-2bf7d71172d5",
    "_cell_guid": "4404650a-ce9e-4f66-afeb-c9489741f794",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:45.876379Z",
     "iopub.execute_input": "2024-12-23T21:57:45.877091Z",
     "iopub.status.idle": "2024-12-23T21:57:46.509487Z",
     "shell.execute_reply.started": "2024-12-23T21:57:45.877063Z",
     "shell.execute_reply": "2024-12-23T21:57:46.508457Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {
    "_uuid": "991080dc-0d08-4682-995f-f14a347ed496",
    "_cell_guid": "bd88869b-92a1-49bd-9b8e-6e39557fdaf1",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Training parameters and setup\n",
    "epochs = 10\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='transformer_language_translation_checkpoint.hdf5', save_weights_only=True, verbose=1, monitor='val_accuracy')\n",
    "\n",
    "transformer_model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "transformer_model.fit(train_ds, epochs=epochs, callbacks=[checkpoint], validation_data=val_ds)\n",
    "\n",
    "# Saving model weights\n",
    "transformer_model.save_weights(\"transformer_translator.h5\")\n",
    "load_status = transformer_model.load_weights(\"transformer_translator.h5\")"
   ],
   "metadata": {
    "_uuid": "69b36f74-fb02-421e-838c-31b2292da1e9",
    "_cell_guid": "944cd8e0-a588-4b11-aa17-49890c25daa5",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T21:57:46.510823Z",
     "iopub.execute_input": "2024-12-23T21:57:46.511107Z",
     "iopub.status.idle": "2024-12-23T22:17:43.805232Z",
     "shell.execute_reply.started": "2024-12-23T21:57:46.511081Z",
     "shell.execute_reply": "2024-12-23T22:17:43.804389Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/10\n1828/1828 [==============================] - 124s 66ms/step - loss: 1.5573 - accuracy: 0.4746 - val_loss: 1.2090 - val_accuracy: 0.5654\n\nEpoch 00001: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 2/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 1.2136 - accuracy: 0.5845 - val_loss: 1.0676 - val_accuracy: 0.6154\n\nEpoch 00002: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 3/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 1.0861 - accuracy: 0.6247 - val_loss: 1.0157 - val_accuracy: 0.6427\n\nEpoch 00003: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 4/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 1.0316 - accuracy: 0.6484 - val_loss: 0.9905 - val_accuracy: 0.6534\n\nEpoch 00004: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 5/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 1.0026 - accuracy: 0.6643 - val_loss: 0.9824 - val_accuracy: 0.6611\n\nEpoch 00005: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 6/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 0.9810 - accuracy: 0.6773 - val_loss: 0.9792 - val_accuracy: 0.6656\n\nEpoch 00006: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 7/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 0.9629 - accuracy: 0.6880 - val_loss: 0.9758 - val_accuracy: 0.6719\n\nEpoch 00007: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 8/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 0.9466 - accuracy: 0.6963 - val_loss: 0.9659 - val_accuracy: 0.6766\n\nEpoch 00008: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 9/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 0.9302 - accuracy: 0.7045 - val_loss: 0.9658 - val_accuracy: 0.6780\n\nEpoch 00009: saving model to transformer_language_translation_checkpoint.hdf5\nEpoch 10/10\n1828/1828 [==============================] - 119s 65ms/step - loss: 0.9152 - accuracy: 0.7117 - val_loss: 0.9650 - val_accuracy: 0.6797\n\nEpoch 00010: saving model to transformer_language_translation_checkpoint.hdf5\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation"
   ],
   "metadata": {
    "_uuid": "abccd2af-59c8-4ddf-adbf-7f41c047bc93",
    "_cell_guid": "d6b4e101-d53c-4021-810f-7f670d1a1a9b",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test data\n",
    "fra_vocab = target_vectorization.get_vocabulary()\n",
    "fra_index_lookup = dict(zip(range(len(fra_vocab)), fra_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence_transformer(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer_model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fra_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence_transformer(input_sentence))"
   ],
   "metadata": {
    "_uuid": "a004ea78-14bd-4a62-bf66-61569ab9ba64",
    "_cell_guid": "d84d8cde-7860-474c-a2fe-bd1e18b2089f",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T22:17:43.806592Z",
     "iopub.execute_input": "2024-12-23T22:17:43.807381Z",
     "iopub.status.idle": "2024-12-23T22:17:44.620758Z",
     "shell.execute_reply.started": "2024-12-23T22:17:43.807340Z",
     "shell.execute_reply": "2024-12-23T22:17:44.619789Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "-\nWe all have different abilities.\n[start] nous avons tous des [UNK] [end]\n-\nHave you called him yet?\n[start] lavezvous déjà appelé [end]\n-\nYou're hurting him.\n[start] tu lui as fait mal [end]\n-\nI don't have a cellphone.\n[start] je nai pas de téléphone [UNK] [end]\n-\nCan you repair this?\n[start] pouvezvous réparer ceci [end]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluation using the BLEU score\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_fra_texts = [pair[1] for pair in test_pairs]\n",
    "score = 0\n",
    "bleu = 0\n",
    "for i in range(20):\n",
    "    candidate = decode_sequence_transformer(test_eng_texts[i])\n",
    "    reference = test_fra_texts[i].lower()\n",
    "    print(candidate, reference)\n",
    "    score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu += score\n",
    "    print(f\"Score: {score}\")\n",
    "print(f\"\\nBLEU score : {round(bleu, 2)}/20\")"
   ],
   "metadata": {
    "_uuid": "d1a2da36-648e-472d-b03d-fe17ffbcc90b",
    "_cell_guid": "b2a0cfff-90e4-4bd1-9349-978bc47c580f",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T22:17:44.622065Z",
     "iopub.execute_input": "2024-12-23T22:17:44.622465Z",
     "iopub.status.idle": "2024-12-23T22:17:49.394421Z",
     "shell.execute_reply.started": "2024-12-23T22:17:44.622433Z",
     "shell.execute_reply": "2024-12-23T22:17:49.393502Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[start] mon peu du le est [UNK] [end] [start] mon petit doigt est enflé. [end]\nScore: 0.3783783783783784\n[start] tu vas avoir du mal à avoir des choses [end] [start] tu vas passer un sale quart d'heure. [end]\nScore: 0.2692307692307693\n[start] il est [UNK] de lire le livre [end] [start] il est impatient de lire le livre. [end]\nScore: 0.3023255813953489\n[start] ils ne peuvent pas vous feu [end] [start] ils ne peuvent pas vous virer. [end]\nScore: 0.3902439024390244\n[start] ne me dis pas si tu ne veux pas [end] [start] ne me le dis pas si tu ne veux pas. [end]\nScore: 0.35555555555555557\n[start] combien dargent astu fait la voiture sur ta voiture [end] [start] combien d'argent as-tu claqué pour ta voiture ? [end]\nScore: 0.2923076923076923\n[start] nous [UNK] pas de ne pas le quitter à nouveau [end] [start] nous essaierons de ne pas laisser cela se reproduire. [end]\nScore: 0.2542372881355932\n[start] nous navons pas pu acheter des [UNK] pour ne pas le film [end] [start] nous n'avons pas pu acheter de places, nous ne sommes donc pas allé au concert. [end]\nScore: 0.2571428571428571\n[start] Êtesvous pour ou contre la proposition [end] [start] es-tu pour ou contre la proposition ? [end]\nScore: 0.30769230769230765\n[start] tu [UNK] [end] [start] tu t'exprimes bien. [end]\nScore: 0.5\n[start] je nai que des cours de [UNK] dans ma lettre maintenant [end] [start] je n'ai que des pièces américaines dans ma poche pour le moment. [end]\nScore: 0.2608695652173913\n[start] le travail était [UNK] en une de [UNK] [end] [start] le jardin était entouré par une barrière en bois. [end]\nScore: 0.2692307692307693\n[start] le parc est près de mon travail [end] [start] central park est proche de mon lieu de travail. [end]\nScore: 0.37777777777777777\n[start] je suis sur le chemin [end] [start] je suis en chemin. [end]\nScore: 0.45714285714285713\n[start] nous avons un problème [end] [start] nous avons un problème. [end]\nScore: 0.5\n[start] je pense que cest une a de [end] [start] je pense que c'est une loi terrible. [end]\nScore: 0.375\n[start] pourquoi ne [UNK] pas ton manteau [end] [start] pourquoi ne retires-tu pas ton manteau ? [end]\nScore: 0.34042553191489366\n[start] je dispose de suffisamment dargent pour le faire [end] [start] je dispose de suffisamment d'argent pour faire son acquisition. [end]\nScore: 0.2903225806451613\n[start] je suis en train de conduire à mon voiture [end] [start] je lave la voiture de mon frère. [end]\nScore: 0.2857142857142857\n[start] astu [UNK] ton professeur de ce [end] [start] as-tu prévenu ton professeur de cela ? [end]\nScore: 0.3333333333333333\n\nBLEU score : 6.8/20\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-trained model from Hugging Face"
   ],
   "metadata": {
    "_uuid": "97d5eb80-48dd-47f0-8643-e3ebccb1344e",
    "_cell_guid": "2bf380ef-e01d-4416-b66e-75ab15fec2ac",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Loading"
   ],
   "metadata": {
    "_uuid": "86cee824-6a39-4251-b0d3-cc93422285a6",
    "_cell_guid": "b8afd41c-5058-48d2-b732-4137c6df66ee",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load pretrained model and tokenizer for English to French translation\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ],
   "metadata": {
    "_uuid": "bd9d4167-1ed8-46a2-989e-cdb10e575e8d",
    "_cell_guid": "5c0242ca-e887-4219-83ed-42f800d17510",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T22:17:49.395711Z",
     "iopub.execute_input": "2024-12-23T22:17:49.396042Z",
     "iopub.status.idle": "2024-12-23T22:17:57.569700Z",
     "shell.execute_reply.started": "2024-12-23T22:17:49.396014Z",
     "shell.execute_reply": "2024-12-23T22:17:57.568758Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference"
   ],
   "metadata": {
    "_uuid": "374bd192-d72f-4c89-baf1-0f2d158fe19d",
    "_cell_guid": "a759251a-7644-40c0-b747-b1919cb2fee6",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def translate_with_huggingface(input_sentence):\n",
    "    # Tokenize the input sentence\n",
    "    tokenized_input_sentence = tokenizer.encode(input_sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Get the prediction from the model\n",
    "    translated = model.generate(tokenized_input_sentence, max_length=50, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the translated sentence\n",
    "    translated_sentence = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return translated_sentence"
   ],
   "metadata": {
    "_uuid": "1a71e3d9-8e71-40eb-b388-ec05d4b6ac80",
    "_cell_guid": "07482606-0c8d-4e2f-9533-0282de892f99",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T22:17:57.571044Z",
     "iopub.execute_input": "2024-12-23T22:17:57.571312Z",
     "iopub.status.idle": "2024-12-23T22:17:57.576679Z",
     "shell.execute_reply.started": "2024-12-23T22:17:57.571284Z",
     "shell.execute_reply": "2024-12-23T22:17:57.575694Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test and Comparison"
   ],
   "metadata": {
    "_uuid": "03cc8f56-f968-4dd4-b31b-bd98717cba39",
    "_cell_guid": "d6caa819-4813-4d79-96c3-22ac9195915b",
    "trusted": true,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Test model on test data\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for input_sentence in test_eng_texts[:5]:  # Adjust to the desired number of sentences\n",
    "    print(\"Original English sentence:\", input_sentence)\n",
    "    \n",
    "    # Translate with Hugging Face model\n",
    "    hf_translation = translate_with_huggingface(input_sentence)\n",
    "    print(\"Hugging Face Translation:\", hf_translation)\n",
    "    print(\"-\" * 50)"
   ],
   "metadata": {
    "_uuid": "a752356e-ac34-4745-bb58-f50d3a9faae5",
    "_cell_guid": "79f48b24-8116-4048-8a76-8994560760b6",
    "trusted": true,
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-23T22:17:57.577847Z",
     "iopub.execute_input": "2024-12-23T22:17:57.578202Z",
     "iopub.status.idle": "2024-12-23T22:17:59.242969Z",
     "shell.execute_reply.started": "2024-12-23T22:17:57.578156Z",
     "shell.execute_reply": "2024-12-23T22:17:59.242154Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Original English sentence: My little finger is swollen.\nHugging Face Translation: Mon petit doigt est gonflé.\n--------------------------------------------------\nOriginal English sentence: You'll have a rough time.\nHugging Face Translation: Vous passerez un moment difficile.\n--------------------------------------------------\nOriginal English sentence: He is anxious to read the book.\nHugging Face Translation: Il est impatient de lire le livre.\n--------------------------------------------------\nOriginal English sentence: They can't fire you.\nHugging Face Translation: Ils ne peuvent pas te virer.\n--------------------------------------------------\nOriginal English sentence: Don't tell me if you don't want to.\nHugging Face Translation: Ne me dis pas si tu ne veux pas.\n--------------------------------------------------\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 26
  }
 ]
}
