{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5193333,"sourceType":"datasetVersion","datasetId":3019642}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pathlib\nimport random\nimport string\nimport re\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import TextVectorization\nfrom tensorflow.keras.layers import Bidirectional,GRU,LSTM,Embedding\nfrom tensorflow.keras.layers import Dense,MultiHeadAttention,LayerNormalization,Embedding,Dropout,Layer\nfrom tensorflow.keras import Sequential,Input\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:46.616164Z","iopub.execute_input":"2024-12-23T18:30:46.616418Z","iopub.status.idle":"2024-12-23T18:30:55.460472Z","shell.execute_reply.started":"2024-12-23T18:30:46.616393Z","shell.execute_reply":"2024-12-23T18:30:55.459748Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the dataset from the provided file\ntext_file = '/kaggle/input/french/fra.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.461258Z","iopub.execute_input":"2024-12-23T18:30:55.461817Z","iopub.status.idle":"2024-12-23T18:30:55.465089Z","shell.execute_reply.started":"2024-12-23T18:30:55.461793Z","shell.execute_reply":"2024-12-23T18:30:55.464170Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"with open(text_file) as f:\n    lines = f.read().split(\"\\n\")[:-1]\n\n# Prepare text pairs (English and French sentences)\ntext_pairs = []\nfor line in lines:\n    english, french = line.split(\"\\t\")\n    french = \"[start] \" + french + \" [end]\"\n    text_pairs.append((english, french))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.466626Z","iopub.execute_input":"2024-12-23T18:30:55.466894Z","iopub.status.idle":"2024-12-23T18:30:55.794490Z","shell.execute_reply.started":"2024-12-23T18:30:55.466861Z","shell.execute_reply":"2024-12-23T18:30:55.793780Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Display a random text pair\nimport random\nprint(random.choice(text_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.795631Z","iopub.execute_input":"2024-12-23T18:30:55.795885Z","iopub.status.idle":"2024-12-23T18:30:55.800460Z","shell.execute_reply.started":"2024-12-23T18:30:55.795856Z","shell.execute_reply":"2024-12-23T18:30:55.799737Z"}},"outputs":[{"name":"stdout","text":"('You knew I was married.', \"[start] Tu savais que j'étais marié. [end]\")\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Shuffle text pairs and split into training, validation, and test datasets\nimport random\nrandom.shuffle(text_pairs)\nnum_val_samples = int(0.15 * len(text_pairs))\nnum_train_samples = len(text_pairs) - 2 * num_val_samples\ntrain_pairs = text_pairs[:num_train_samples]\nval_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\ntest_pairs = text_pairs[num_train_samples + num_val_samples:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.801367Z","iopub.execute_input":"2024-12-23T18:30:55.801674Z","iopub.status.idle":"2024-12-23T18:30:55.911921Z","shell.execute_reply.started":"2024-12-23T18:30:55.801644Z","shell.execute_reply":"2024-12-23T18:30:55.911265Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define characters to strip from the text\nstrip_chars = string.punctuation + \"¿\"\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.912655Z","iopub.execute_input":"2024-12-23T18:30:55.912886Z","iopub.status.idle":"2024-12-23T18:30:55.916548Z","shell.execute_reply.started":"2024-12-23T18:30:55.912859Z","shell.execute_reply":"2024-12-23T18:30:55.915890Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Custom standardization function for text preprocessing\ndef custom_standardization(input_string):\n    lowercase = tf.strings.lower(input_string)\n    return tf.strings.regex_replace(\n        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.917373Z","iopub.execute_input":"2024-12-23T18:30:55.917594Z","iopub.status.idle":"2024-12-23T18:30:55.932505Z","shell.execute_reply.started":"2024-12-23T18:30:55.917568Z","shell.execute_reply":"2024-12-23T18:30:55.931831Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Set parameters for text vectorization\nvocab_size = 15000\nsequence_length = 20\n\n# Initialize TextVectorization layers for source and target languages\nsource_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n)\ntarget_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length + 1,\n    standardize=custom_standardization,\n)\n\n# Adapt the vectorization layers using the training data\ntrain_english_texts = [pair[0] for pair in train_pairs]\ntrain_french_texts = [pair[1] for pair in train_pairs]\nsource_vectorization.adapt(train_english_texts)\ntarget_vectorization.adapt(train_french_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:55.935055Z","iopub.execute_input":"2024-12-23T18:30:55.935256Z","iopub.status.idle":"2024-12-23T18:30:57.520421Z","shell.execute_reply.started":"2024-12-23T18:30:55.935239Z","shell.execute_reply":"2024-12-23T18:30:57.519476Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Set batch size for training\nbatch_size = 64\n\n# Function to format dataset for training\ndef format_dataset(eng, fre):\n    eng = source_vectorization(eng)\n    fre = target_vectorization(fre)\n    return ({\n        \"english\": eng,\n        \"french\": fre[:, :-1],\n    }, fre[:, 1:])\n\n# Function to create a TensorFlow dataset from text pairs\ndef make_dataset(pairs):\n    eng_texts, fre_texts = zip(*pairs)\n    eng_texts = list(eng_texts)\n    fre_texts = list(fre_texts)\n    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fre_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n    return dataset.shuffle(2048).prefetch(16).cache()\n\n# Create training and validation datasets\ntrain_ds = make_dataset(train_pairs)\nval_ds = make_dataset(val_pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:57.522034Z","iopub.execute_input":"2024-12-23T18:30:57.522283Z","iopub.status.idle":"2024-12-23T18:30:58.837909Z","shell.execute_reply.started":"2024-12-23T18:30:57.522262Z","shell.execute_reply":"2024-12-23T18:30:58.836992Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## LSTM Model","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:58.838863Z","iopub.execute_input":"2024-12-23T18:30:58.839107Z","iopub.status.idle":"2024-12-23T18:30:58.843261Z","shell.execute_reply.started":"2024-12-23T18:30:58.839086Z","shell.execute_reply":"2024-12-23T18:30:58.842393Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Define the LSTM model architecture\nembed_dim = 256\nlstm_units = 512\n\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\nx = Embedding(vocab_size, embed_dim, mask_zero=True)(encoder_inputs)\nencoder_outputs, state_h, state_c = LSTM(lstm_units, return_state=True)(x)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"french\")\nx = Embedding(vocab_size, embed_dim, mask_zero=True)(decoder_inputs)\nx = LSTM(lstm_units, return_sequences=True, return_state=True)(x, initial_state=encoder_states)\ndecoder_outputs = Dense(vocab_size, activation=\"softmax\")(x[0])\n\nlstm_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:58.844115Z","iopub.execute_input":"2024-12-23T18:30:58.844404Z","iopub.status.idle":"2024-12-23T18:30:59.699125Z","shell.execute_reply.started":"2024-12-23T18:30:58.844377Z","shell.execute_reply":"2024-12-23T18:30:59.698442Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Training parameters and setup\nepochs = 10\n\ncheckpoint = ModelCheckpoint(filepath='lstm_language_translation_checkpoint.weights.h5', save_weights_only=True, verbose=1, monitor='val_accuracy')\n\nlstm_model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# Train the model\nlstm_model.fit(train_ds, epochs=epochs, callbacks=[checkpoint], validation_data=val_ds)\n\n# Saving model weights\nlstm_model.save_weights(\"lstm_translator.weights.h5\")\nload_status = lstm_model.load_weights(\"lstm_translator.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:30:59.699958Z","iopub.execute_input":"2024-12-23T18:30:59.700174Z","iopub.status.idle":"2024-12-23T18:52:36.806301Z","shell.execute_reply.started":"2024-12-23T18:30:59.700156Z","shell.execute_reply":"2024-12-23T18:52:36.805590Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2294 - loss: 5.2631\nEpoch 1: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 71ms/step - accuracy: 0.2294 - loss: 5.2628 - val_accuracy: 0.1566 - val_loss: 4.0031\nEpoch 2/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.1642 - loss: 3.8697\nEpoch 2: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.1643 - loss: 3.8696 - val_accuracy: 0.1834 - val_loss: 3.3943\nEpoch 3/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.1885 - loss: 3.3268\nEpoch 3: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 71ms/step - accuracy: 0.1885 - loss: 3.3268 - val_accuracy: 0.2018 - val_loss: 3.0271\nEpoch 4/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2059 - loss: 2.9678\nEpoch 4: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.2059 - loss: 2.9678 - val_accuracy: 0.2147 - val_loss: 2.7770\nEpoch 5/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2202 - loss: 2.6952\nEpoch 5: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.2202 - loss: 2.6952 - val_accuracy: 0.2259 - val_loss: 2.5764\nEpoch 6/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2331 - loss: 2.4657\nEpoch 6: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.2331 - loss: 2.4657 - val_accuracy: 0.2362 - val_loss: 2.4090\nEpoch 7/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2446 - loss: 2.2671\nEpoch 7: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.2446 - loss: 2.2670 - val_accuracy: 0.2450 - val_loss: 2.2645\nEpoch 8/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2551 - loss: 2.0944\nEpoch 8: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.2551 - loss: 2.0943 - val_accuracy: 0.2525 - val_loss: 2.1460\nEpoch 9/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2645 - loss: 1.9425\nEpoch 9: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 71ms/step - accuracy: 0.2645 - loss: 1.9425 - val_accuracy: 0.2590 - val_loss: 2.0486\nEpoch 10/10\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2733 - loss: 1.8083\nEpoch 10: saving model to lstm_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 70ms/step - accuracy: 0.2733 - loss: 1.8083 - val_accuracy: 0.2638 - val_loss: 1.9730\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Evaluate the model on the test data\nfra_vocab = target_vectorization.get_vocabulary()\nfra_index_lookup = dict(zip(range(len(fra_vocab)), fra_vocab))\nmax_decoded_sentence_length = 20\n\ndef decode_sequence_lstm(input_sentence):\n    tokenized_input_sentence = source_vectorization([input_sentence])\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n        predictions = lstm_model([tokenized_input_sentence, tokenized_target_sentence])\n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = fra_index_lookup[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n        if sampled_token == \"[end]\":\n            break\n    return decoded_sentence\n\ntest_eng_texts = [pair[0] for pair in test_pairs]\nfor _ in range(5):\n    input_sentence = random.choice(test_eng_texts)\n    print(\"-\")\n    print(input_sentence)\n    print(decode_sequence_lstm(input_sentence))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:36.807062Z","iopub.execute_input":"2024-12-23T18:52:36.807279Z","iopub.status.idle":"2024-12-23T18:52:38.263166Z","shell.execute_reply.started":"2024-12-23T18:52:36.807261Z","shell.execute_reply":"2024-12-23T18:52:38.262275Z"}},"outputs":[{"name":"stdout","text":"-\nShe helped me out countless times.\n[start] elle ma appelé plusieurs fois [end]\n-\nThere's no need to call a doctor.\n[start] il ne faut pas quil faut un médecin [end]\n-\nI mean you no harm.\n[start] je ne veux pas que vous ne soyez pas mal [end]\n-\nStop talking to me about Tom.\n[start] arrêtez de parler avec tom [end]\n-\nWe're less than halfway to the top of the mountain. Are you already tired?\n[start] nous sommes à la moitié du chemin et je suis déjà à court de main [end]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Evaluation using the BLEU score\ntest_eng_texts = [pair[0] for pair in test_pairs]\ntest_fra_texts = [pair[1] for pair in test_pairs]\nscore = 0\nbleu = 0\nfor i in range(20):\n    candidate = decode_sequence_lstm(test_eng_texts[i])\n    reference = test_fra_texts[i].lower()\n    print(candidate, reference)\n    score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n    bleu += score\n    print(f\"Score: {score}\")\nprint(f\"\\nBLEU score : {round(bleu, 2)}/20\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:38.263953Z","iopub.execute_input":"2024-12-23T18:52:38.264166Z","iopub.status.idle":"2024-12-23T18:52:41.775132Z","shell.execute_reply.started":"2024-12-23T18:52:38.264148Z","shell.execute_reply":"2024-12-23T18:52:41.774377Z"}},"outputs":[{"name":"stdout","text":"[start] jai une proposition [end] [start] j'ai une proposition. [end]\nScore: 0.45454545454545453\n[start] jai tous mes amis [end] [start] j'ai toutes les amies dont j'ai besoin. [end]\nScore: 0.4838709677419355\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"[start] où êtesvous [end] [start] où étais-tu ? [end]\nScore: 0.52\n[start] nous nous [UNK] [end] [start] nous nous sommes amusées avec elles. [end]\nScore: 0.41379310344827586\n[start] je veux que tu [UNK] [end] [start] je veux que vous me parliez. [end]\nScore: 0.4411764705882353\n[start] tu peux nager [end] [start] tu peux nager. [end]\nScore: 0.5185185185185185\n[start] je ne savais pas que tom était mort [end] [start] je ne savais pas que tom était décédé. [end]\nScore: 0.3877551020408163\n[start] cest un homme à la personne [end] [start] c’est un homme de caractère. [end]\nScore: 0.3658536585365854\n[start] je ne veux même pas savoir ce que nous ne pouvons pas faire [end] [start] je ne veux même pas songer à ce qui pourrait se produire. [end]\nScore: 0.2876712328767123\n[start] comment sappelle [end] [start] comment s'appelle-t-il ? [end]\nScore: 0.5\n[start] voici ma chambre [end] [start] voici ma chambre ! [end]\nScore: 0.5666666666666667\n[start] les choses ne peuvent pas me [UNK] [end] [start] je ne peux exprimer ce que je ressens avec des mots. [end]\nScore: 0.3333333333333333\n[start] ce film est à lécole [end] [start] ce film fait peur aux enfants. [end]\nScore: 0.4411764705882353\n[start] lécole est à la gare [end] [start] l'école est finie. [end]\nScore: 0.4117647058823529\n[start] jai besoin de [UNK] [end] [start] j'ai besoin de sous-titres. [end]\nScore: 0.42424242424242425\n[start] Êtesvous fatigué de vivre [end] [start] es-tu fatigué de vivre ? [end]\nScore: 0.41025641025641024\n[start] ditesnous ce qui sest passé [end] [start] dites-nous exactement ce qu'il s'est passé. [end]\nScore: 0.4146341463414634\n[start] je pensais que vous [UNK] toutes les [UNK] [end] [start] je pensais que tu disposais de toutes les réponses. [end]\nScore: 0.30357142857142855\n[start] tout le monde était très belle [end] [start] tout le monde n'a pas été impressionné. [end]\nScore: 0.36363636363636365\n[start] comment [UNK] nos dettes [end] [start] comment payerons-nous désormais nos dettes ? [end]\nScore: 0.3421052631578948\n\nBLEU score : 8.38/20\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Transformer Model","metadata":{}},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Embedding, Dense, LayerNormalization, MultiHeadAttention, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:41.775899Z","iopub.execute_input":"2024-12-23T18:52:41.776133Z","iopub.status.idle":"2024-12-23T18:52:41.780085Z","shell.execute_reply.started":"2024-12-23T18:52:41.776108Z","shell.execute_reply":"2024-12-23T18:52:41.779299Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Define the Transformer Encoder class\nclass TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, dense_dim, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.dense_dim = dense_dim\n        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = keras.Sequential([Dense(dense_dim, activation=\"relu\"), Dense(embed_dim)])\n        self.layernorm_1 = LayerNormalization()\n        self.layernorm_2 = LayerNormalization()\n\n    def call(self, inputs):\n        attention_output = self.attention(inputs, inputs, inputs)\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:41.780982Z","iopub.execute_input":"2024-12-23T18:52:41.781210Z","iopub.status.idle":"2024-12-23T18:52:42.062981Z","shell.execute_reply.started":"2024-12-23T18:52:41.781191Z","shell.execute_reply":"2024-12-23T18:52:42.062202Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Define the Transformer Decoder class\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, dense_dim, **kwargs):\n        super(TransformerDecoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.dense_dim = dense_dim\n        self.attention_1 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.attention_2 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = keras.Sequential([Dense(dense_dim, activation=\"relu\"), Dense(embed_dim)])\n        self.layernorm_1 = LayerNormalization()\n        self.layernorm_2 = LayerNormalization()\n\n    def call(self, inputs, encoder_outputs):\n        attention_output_1 = self.attention_1(inputs, inputs, inputs)\n        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n        attention_output_2 = self.attention_2(attention_output_1, encoder_outputs, encoder_outputs)\n        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n        proj_output = self.dense_proj(attention_output_2)\n        return attention_output_2 + proj_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:42.063897Z","iopub.execute_input":"2024-12-23T18:52:42.064183Z","iopub.status.idle":"2024-12-23T18:52:42.079671Z","shell.execute_reply.started":"2024-12-23T18:52:42.064154Z","shell.execute_reply":"2024-12-23T18:52:42.078888Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Define the Positional Embedding class\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, embed_dim, **kwargs):\n        super(PositionalEmbedding, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.sequence_length = sequence_length\n\n    def build(self, input_shape):\n        # Initialize positional embedding\n        self.pos_embedding = self.add_weight(\n            name=\"pos_embedding\",\n            shape=(self.sequence_length, self.embed_dim),  # Shape based on sequence_length\n            initializer=\"zeros\",\n            trainable=True\n        )\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-2]  # Get the sequence length from inputs (batch size is ignored)\n        return inputs + self.pos_embedding[:length, :]  # Slice pos_embedding based on sequence length\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:42.080507Z","iopub.execute_input":"2024-12-23T18:52:42.080797Z","iopub.status.idle":"2024-12-23T18:52:42.093010Z","shell.execute_reply.started":"2024-12-23T18:52:42.080767Z","shell.execute_reply":"2024-12-23T18:52:42.092269Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Define the Positional Embedding class\nclass PositionalEmbedding(Layer):\n    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.token_embeddings = Embedding(\n            input_dim=input_dim, output_dim=output_dim)\n        print(input_dim,output_dim)\n        #intermediate = self.getPositionEncoding(seq_len=input_dim,d=vocab_size,n=output_dim)\n        self.position_embeddings = Embedding(input_dim=input_dim, output_dim=output_dim)\n        self.sequence_length = sequence_length\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n\n    def getPositionEncoding(self,seq_len, d, n = sequence_length):\n        P = np.zeros((seq_len, d))\n        for k in range(seq_len):\n            for i in np.arange(int(d/2)):\n                denominator = np.power(n, 2*i/d)\n                P[k, 2*i] = np.sin(k/denominator)\n                P[k, 2*i+1] = np.cos(k/denominator)\n        tensor = tf.convert_to_tensor(P)\n        print(tensor.shape)\n        return tensor\n    \n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n\n    def get_config(self):\n        config = super(PositionalEmbedding, self).get_config()\n        config.update({\n            \"output_dim\": self.output_dim,\n            \"sequence_length\": self.sequence_length,\n            \"input_dim\": self.input_dim,\n        })\n        return config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:10:41.491114Z","iopub.execute_input":"2024-12-23T19:10:41.491438Z","iopub.status.idle":"2024-12-23T19:10:41.499070Z","shell.execute_reply.started":"2024-12-23T19:10:41.491411Z","shell.execute_reply":"2024-12-23T19:10:41.498256Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Build the Transformer model architecture\nembed_dim = 256\ndense_dim = 2048\nnum_heads = 8\n\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"french\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\nx = Dropout(0.5)(x)\ndecoder_outputs = Dense(vocab_size, activation=\"softmax\")(x)\ntransformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:16:53.879812Z","iopub.execute_input":"2024-12-23T19:16:53.880184Z","iopub.status.idle":"2024-12-23T19:16:53.976154Z","shell.execute_reply.started":"2024-12-23T19:16:53.880156Z","shell.execute_reply":"2024-12-23T19:16:53.975105Z"}},"outputs":[{"name":"stdout","text":"15000 256\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-d16d00385371>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-5ba321e0b154>\u001b[0m in \u001b[0;36mcompute_mask\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"],"ename":"ValueError","evalue":"A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"# Build the Transformer model architecture\nembed_dim = 256\ndense_dim = 2048\nnum_heads = 8\n\n# Encoder\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\nx = Embedding(vocab_size, embed_dim)(encoder_inputs)\nx = PositionalEmbedding(sequence_length, embed_dim)(x)\nencoder_outputs = TransformerEncoder(embed_dim, num_heads, dense_dim)(x)\n\n# Decoder\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"french\")\nx = Embedding(vocab_size, embed_dim)(decoder_inputs)\nx = PositionalEmbedding(sequence_length, embed_dim)(x)\nx = TransformerDecoder(embed_dim, num_heads, dense_dim)(x, encoder_outputs)\nx = Dropout(0.5)(x)\ndecoder_outputs = Dense(vocab_size, activation=\"softmax\")(x)\n\n# Final model\ntransformer_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:10:22.619774Z","iopub.execute_input":"2024-12-23T19:10:22.620149Z","iopub.status.idle":"2024-12-23T19:10:23.067474Z","shell.execute_reply.started":"2024-12-23T19:10:22.620120Z","shell.execute_reply":"2024-12-23T19:10:23.066782Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Training parameters and setup\nepochs = 10\n\ncheckpoint = ModelCheckpoint(filepath='transformer_language_translation_checkpoint.weights.h5', save_weights_only=True, verbose=1, monitor='val_accuracy')\n\ntransformer_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# Assuming `train_ds` and `val_ds` are pre-defined datasets\ntransformer_model.fit(train_ds, epochs=epochs, callbacks=[checkpoint], validation_data=val_ds)\n\n# Saving model weights\ntransformer_model.save_weights(\"transformer_translator.weights.h5\")\nload_status = transformer_model.load_weights(\"transformer_translator.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:52:42.783223Z","iopub.execute_input":"2024-12-23T18:52:42.783428Z","iopub.status.idle":"2024-12-23T19:01:57.894664Z","shell.execute_reply.started":"2024-12-23T18:52:42.783410Z","shell.execute_reply":"2024-12-23T19:01:57.893975Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8254 - loss: 1.2854\nEpoch 1: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 32ms/step - accuracy: 0.8255 - loss: 1.2847 - val_accuracy: 0.9877 - val_loss: 0.0887\nEpoch 2/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.1130\nEpoch 2: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 29ms/step - accuracy: 0.9831 - loss: 0.1129 - val_accuracy: 0.9952 - val_loss: 0.0314\nEpoch 3/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0510\nEpoch 3: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 29ms/step - accuracy: 0.9903 - loss: 0.0510 - val_accuracy: 0.9982 - val_loss: 0.0099\nEpoch 4/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9941 - loss: 0.0264\nEpoch 4: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 30ms/step - accuracy: 0.9941 - loss: 0.0264 - val_accuracy: 0.9993 - val_loss: 0.0038\nEpoch 5/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0157\nEpoch 5: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 30ms/step - accuracy: 0.9961 - loss: 0.0157 - val_accuracy: 0.9995 - val_loss: 0.0024\nEpoch 6/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9954 - loss: 0.0252\nEpoch 6: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 29ms/step - accuracy: 0.9954 - loss: 0.0252 - val_accuracy: 0.9998 - val_loss: 0.0017\nEpoch 7/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0070\nEpoch 7: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 29ms/step - accuracy: 0.9983 - loss: 0.0070 - val_accuracy: 0.9998 - val_loss: 0.0017\nEpoch 8/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0076\nEpoch 8: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 30ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.9998 - val_loss: 0.0013\nEpoch 9/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0085\nEpoch 9: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 30ms/step - accuracy: 0.9979 - loss: 0.0085 - val_accuracy: 0.9998 - val_loss: 0.0021\nEpoch 10/10\n\u001b[1m1827/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0083\nEpoch 10: saving model to transformer_language_translation_checkpoint.weights.h5\n\u001b[1m1828/1828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0083 - val_accuracy: 0.9999 - val_loss: 0.0010\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Evaluate the model on the test data\nfra_vocab = target_vectorization.get_vocabulary()\nfra_index_lookup = dict(zip(range(len(fra_vocab)), fra_vocab))\nmax_decoded_sentence_length = 20\n\ndef decode_sequence_transformer(input_sentence):\n    tokenized_input_sentence = source_vectorization([input_sentence])\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n        predictions = transformer_model([tokenized_input_sentence, tokenized_target_sentence])\n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = fra_index_lookup[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n        if sampled_token == \"[end]\":\n            break\n    return decoded_sentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:01:57.895613Z","iopub.execute_input":"2024-12-23T19:01:57.895934Z","iopub.status.idle":"2024-12-23T19:01:57.939855Z","shell.execute_reply.started":"2024-12-23T19:01:57.895892Z","shell.execute_reply":"2024-12-23T19:01:57.939198Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Evaluation using the BLEU score\nscore = 0\nbleu = 0\nfor i in range(20):\n    candidate = decode_sequence_transformer(test_eng_texts[i])\n    reference = test_fra_texts[i].lower()\n    score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n    bleu += score\n    print(f\"Score: {score}\")\nprint(f\"\\nBLEU score : {round(bleu, 2)}/20\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:01:57.940517Z","iopub.execute_input":"2024-12-23T19:01:57.940736Z","iopub.status.idle":"2024-12-23T19:02:17.354721Z","shell.execute_reply.started":"2024-12-23T19:01:57.940716Z","shell.execute_reply":"2024-12-23T19:02:17.353984Z"}},"outputs":[{"name":"stdout","text":"Score: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\nScore: 0.25925925925925924\n\nBLEU score : 5.19/20\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"--------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, Dropout, LayerNormalization, Dense\nfrom tensorflow.keras.models import Model\n\n# Parameters\nembed_dim = 256\nnum_heads = 8\ndense_dim = 512  # Dimension for the dense layer\nnum_layers = 2  # Number of transformer layers\ndropout_rate = 0.1\n\n# Input layer\ninputs = Input(shape=(None,), dtype=\"int64\", name=\"inputs\")\n\n# Embedding layer\nembedding = Embedding(vocab_size, embed_dim)(inputs)\n\n# Positional Encoding using tf.keras.layers.Embedding for simplicity\npos_encoding = Embedding(input_dim=sequence_length, output_dim=embed_dim)(tf.range(sequence_length))\n\n# Add positional encoding to the embedding\nx = embedding + pos_encoding\n\n# Add transformer layers\nfor _ in range(num_layers):\n    # Multi-Head Attention\n    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)\n    attn_output = Dropout(dropout_rate)(attn_output)\n    x = LayerNormalization(epsilon=1e-6)(x + attn_output)\n\n    # Feed-forward network\n    ffn_output = Dense(dense_dim, activation=\"relu\")(x)\n    ffn_output = Dense(embed_dim)(ffn_output)\n    ffn_output = Dropout(dropout_rate)(ffn_output)\n    x = LayerNormalization(epsilon=1e-6)(x + ffn_output)\n\n# Final output layer\noutputs = Dense(vocab_size, activation=\"softmax\")(x)\n\n# Build the model\nmodel = Model(inputs, outputs)\n\n# Summary of the model\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:37:20.564156Z","iopub.execute_input":"2024-12-23T19:37:20.564468Z","iopub.status.idle":"2024-12-23T19:37:20.707541Z","shell.execute_reply.started":"2024-12-23T19:37:20.564444Z","shell.execute_reply":"2024-12-23T19:37:20.706762Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_9\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ inputs (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,840,000\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ embedding_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_8    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m2,103,552\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│                           │                        │                │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │            \u001b[38;5;34m512\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m131,328\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │            \u001b[38;5;34m512\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_9    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │            \u001b[38;5;34m512\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m131,328\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │            \u001b[38;5;34m512\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15000\u001b[0m)      │      \u001b[38;5;34m3,855,000\u001b[0m │ layer_normalization_1… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_8    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│                           │                        │                │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_9    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ layer_normalization_1… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,429,976\u001b[0m (47.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,429,976</span> (47.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,429,976\u001b[0m (47.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,429,976</span> (47.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, batch_size=64, epochs=10)\npredictions = model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:37:24.608342Z","iopub.execute_input":"2024-12-23T19:37:24.608748Z","iopub.status.idle":"2024-12-23T19:37:24.640329Z","shell.execute_reply.started":"2024-12-23T19:37:24.608710Z","shell.execute_reply":"2024-12-23T19:37:24.638984Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-952c22726ef8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"],"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error"}],"execution_count":37},{"cell_type":"markdown","source":"## Pre-trained model from Hugging Face","metadata":{}},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\n\n# Load pretrained model and tokenizer for English to French translation\nmodel_name = \"Helsinki-NLP/opus-mt-en-fr\"\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:02:17.357758Z","iopub.execute_input":"2024-12-23T19:02:17.357997Z","iopub.status.idle":"2024-12-23T19:02:27.455288Z","shell.execute_reply.started":"2024-12-23T19:02:17.357977Z","shell.execute_reply":"2024-12-23T19:02:27.454002Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91febd5812994765972ad379d407b194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae74418e53ab4a199ec36ba6509591ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8777de1cbb44a099594c6fa4392240a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f655ccc47c45369f5471cbd410fdbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420ff90397a1415b83e31545cd78c083"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bbede1869e4990ba3a42b1ae953034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"688bde1d0a7e4d63a0670066b6e56021"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"def translate_with_huggingface(input_sentence):\n    # Tokenize the input sentence\n    tokenized_input_sentence = tokenizer.encode(input_sentence, return_tensors=\"pt\", padding=True, truncation=True)\n    \n    # Get the prediction from the model\n    translated = model.generate(tokenized_input_sentence, max_length=50, num_beams=4, early_stopping=True)\n    \n    # Decode the translated sentence\n    translated_sentence = tokenizer.decode(translated[0], skip_special_tokens=True)\n    return translated_sentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:02:27.456558Z","iopub.execute_input":"2024-12-23T19:02:27.457337Z","iopub.status.idle":"2024-12-23T19:02:27.462735Z","shell.execute_reply.started":"2024-12-23T19:02:27.457293Z","shell.execute_reply":"2024-12-23T19:02:27.461801Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Test with both models\ntest_eng_texts = [pair[0] for pair in test_pairs]\nfor input_sentence in test_eng_texts[:5]:  # Adjust to the desired number of sentences\n    print(\"Original English sentence:\", input_sentence)\n    \n    # Translate with LSTM model\n    LSTM_translation = decode_sequence_lstm(input_sentence)\n    print(\"LSTM Translation:\", LSTM_translation)\n\n    # Translate with Transformer model\n    transformer_translation = decode_sequence_transformer(input_sentence)\n    print(\"Transformer Translation:\", transformer_translation)\n    \n    # Translate with Hugging Face model\n    hf_translation = translate_with_huggingface(input_sentence)\n    print(\"Hugging Face Translation:\", hf_translation)\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T19:02:27.463641Z","iopub.execute_input":"2024-12-23T19:02:27.463907Z","iopub.status.idle":"2024-12-23T19:02:34.396002Z","shell.execute_reply.started":"2024-12-23T19:02:27.463877Z","shell.execute_reply":"2024-12-23T19:02:34.395088Z"}},"outputs":[{"name":"stdout","text":"Original English sentence: I have a proposal.\nLSTM Translation: [start] jai une proposition [end]\nTransformer Translation: [start]                    \nHugging Face Translation: J'ai une proposition.\n--------------------------------------------------\nOriginal English sentence: I've got all the friends I need.\nLSTM Translation: [start] jai tous mes amis [end]\nTransformer Translation: [start]                    \nHugging Face Translation: J'ai tous les amis dont j'ai besoin.\n--------------------------------------------------\nOriginal English sentence: Where were you?\nLSTM Translation: [start] où êtesvous [end]\nTransformer Translation: [start]                    \nHugging Face Translation: Où étais-tu?\n--------------------------------------------------\nOriginal English sentence: We had fun with them.\nLSTM Translation: [start] nous nous [UNK] [end]\nTransformer Translation: [start]                    \nHugging Face Translation: On s'est amusés avec eux.\n--------------------------------------------------\nOriginal English sentence: I want you to talk to me.\nLSTM Translation: [start] je veux que tu [UNK] [end]\nTransformer Translation: [start]                    \nHugging Face Translation: Je veux que tu me parles.\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":25}]}